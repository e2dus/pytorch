{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b69d706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7580a128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x274e4e69ef0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "83ff6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 3]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e8a446ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c7d78661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2d876202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e^1 equals: tensor([2.7183])\n"
     ]
    }
   ],
   "source": [
    "print('e^1 equals:', torch.exp(torch.FloatTensor([1])))#exponential function의 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "29246abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((2, 1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a09e9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = 1/ (1 + torch.exp(-(x_train.matmul(W)+b))) #x*w = torch.matmul(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "213f1cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<MulBackward0>)\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(hypothesis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9d9e8a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/(1+e^{-1}) equals:  tensor([0.7311])\n"
     ]
    }
   ],
   "source": [
    "print('1/(1+e^{-1}) equals: ', torch.sigmoid(torch.FloatTensor([1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "db4fb60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5ee27230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(hypothesis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "08a48be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6931], grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(y_train[0]*torch.log(hypothesis[0])+ (1-y_train[0])* torch.log(1 - hypothesis[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3940cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931]], grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses =  -(y_train*torch.log(hypothesis)+ \n",
    "            (1-y_train)* torch.log(1 - hypothesis))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3419b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = losses.mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "07263581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c2feee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.693147\n",
      "Epoch  100/1000 Cost: 0.129368\n",
      "Epoch  200/1000 Cost: 0.078759\n",
      "Epoch  300/1000 Cost: 0.057077\n",
      "Epoch  400/1000 Cost: 0.044895\n",
      "Epoch  500/1000 Cost: 0.037049\n",
      "Epoch  600/1000 Cost: 0.031560\n",
      "Epoch  700/1000 Cost: 0.027498\n",
      "Epoch  800/1000 Cost: 0.024368\n",
      "Epoch  900/1000 Cost: 0.021881\n",
      "Epoch 1000/1000 Cost: 0.019856\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([W, b], lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs +1):\n",
    "    hypothesis = torch.sigmoid(x_train.matmul(W)+b)\n",
    "    cost= F.binary_cross_entropy(hypothesis, y_train)\n",
    "    optimizer.zero_grad() # grad를 구한게 있으면 0으로 처리\n",
    "    cost.backward() #cost에다가 backpropagation 수행\n",
    "    optimizer.step() #cost 값을 minimize하는 방향으로 업데이트를 한다. \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs,  cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "40c96823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid= nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fda2c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e1238683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 0.551150 Accuracy 83.33%\n",
      "Epoch    1/100 Cost: 0.566579 Accuracy 66.67%\n",
      "Epoch    2/100 Cost: 0.855197 Accuracy 50.00%\n",
      "Epoch    3/100 Cost: 2.052620 Accuracy 50.00%\n",
      "Epoch    4/100 Cost: 0.455371 Accuracy 83.33%\n",
      "Epoch    5/100 Cost: 0.461365 Accuracy 83.33%\n",
      "Epoch    6/100 Cost: 0.537601 Accuracy 83.33%\n",
      "Epoch    7/100 Cost: 0.742166 Accuracy 50.00%\n",
      "Epoch    8/100 Cost: 1.648683 Accuracy 50.00%\n",
      "Epoch    9/100 Cost: 0.413893 Accuracy 83.33%\n",
      "Epoch   10/100 Cost: 0.415840 Accuracy 83.33%\n",
      "Epoch   11/100 Cost: 0.435836 Accuracy 66.67%\n",
      "Epoch   12/100 Cost: 0.553400 Accuracy 83.33%\n",
      "Epoch   13/100 Cost: 0.601067 Accuracy 66.67%\n",
      "Epoch   14/100 Cost: 1.163023 Accuracy 50.00%\n",
      "Epoch   15/100 Cost: 0.424122 Accuracy 66.67%\n",
      "Epoch   16/100 Cost: 0.532746 Accuracy 83.33%\n",
      "Epoch   17/100 Cost: 0.494740 Accuracy 66.67%\n",
      "Epoch   18/100 Cost: 0.791055 Accuracy 66.67%\n",
      "Epoch   19/100 Cost: 0.444038 Accuracy 66.67%\n",
      "Epoch   20/100 Cost: 0.627249 Accuracy 66.67%\n",
      "Epoch   21/100 Cost: 0.435866 Accuracy 66.67%\n",
      "Epoch   22/100 Cost: 0.616931 Accuracy 66.67%\n",
      "Epoch   23/100 Cost: 0.414391 Accuracy 66.67%\n",
      "Epoch   24/100 Cost: 0.567454 Accuracy 83.33%\n",
      "Epoch   25/100 Cost: 0.399327 Accuracy 83.33%\n",
      "Epoch   26/100 Cost: 0.540416 Accuracy 83.33%\n",
      "Epoch   27/100 Cost: 0.384830 Accuracy 83.33%\n",
      "Epoch   28/100 Cost: 0.515399 Accuracy 83.33%\n",
      "Epoch   29/100 Cost: 0.371414 Accuracy 83.33%\n",
      "Epoch   30/100 Cost: 0.493301 Accuracy 83.33%\n",
      "Epoch   31/100 Cost: 0.358710 Accuracy 83.33%\n",
      "Epoch   32/100 Cost: 0.472664 Accuracy 83.33%\n",
      "Epoch   33/100 Cost: 0.346565 Accuracy 83.33%\n",
      "Epoch   34/100 Cost: 0.452908 Accuracy 83.33%\n",
      "Epoch   35/100 Cost: 0.334872 Accuracy 83.33%\n",
      "Epoch   36/100 Cost: 0.433703 Accuracy 83.33%\n",
      "Epoch   37/100 Cost: 0.323554 Accuracy 83.33%\n",
      "Epoch   38/100 Cost: 0.414868 Accuracy 83.33%\n",
      "Epoch   39/100 Cost: 0.312552 Accuracy 83.33%\n",
      "Epoch   40/100 Cost: 0.396309 Accuracy 83.33%\n",
      "Epoch   41/100 Cost: 0.301821 Accuracy 83.33%\n",
      "Epoch   42/100 Cost: 0.377981 Accuracy 83.33%\n",
      "Epoch   43/100 Cost: 0.291320 Accuracy 83.33%\n",
      "Epoch   44/100 Cost: 0.359871 Accuracy 83.33%\n",
      "Epoch   45/100 Cost: 0.281016 Accuracy 83.33%\n",
      "Epoch   46/100 Cost: 0.341992 Accuracy 83.33%\n",
      "Epoch   47/100 Cost: 0.270886 Accuracy 83.33%\n",
      "Epoch   48/100 Cost: 0.324374 Accuracy 83.33%\n",
      "Epoch   49/100 Cost: 0.260912 Accuracy 83.33%\n",
      "Epoch   50/100 Cost: 0.307070 Accuracy 83.33%\n",
      "Epoch   51/100 Cost: 0.251085 Accuracy 83.33%\n",
      "Epoch   52/100 Cost: 0.290149 Accuracy 83.33%\n",
      "Epoch   53/100 Cost: 0.241409 Accuracy 100.00%\n",
      "Epoch   54/100 Cost: 0.273704 Accuracy 83.33%\n",
      "Epoch   55/100 Cost: 0.231899 Accuracy 100.00%\n",
      "Epoch   56/100 Cost: 0.257846 Accuracy 83.33%\n",
      "Epoch   57/100 Cost: 0.222587 Accuracy 100.00%\n",
      "Epoch   58/100 Cost: 0.242703 Accuracy 83.33%\n",
      "Epoch   59/100 Cost: 0.213521 Accuracy 100.00%\n",
      "Epoch   60/100 Cost: 0.228418 Accuracy 83.33%\n",
      "Epoch   61/100 Cost: 0.204765 Accuracy 100.00%\n",
      "Epoch   62/100 Cost: 0.215138 Accuracy 83.33%\n",
      "Epoch   63/100 Cost: 0.196397 Accuracy 100.00%\n",
      "Epoch   64/100 Cost: 0.203001 Accuracy 83.33%\n",
      "Epoch   65/100 Cost: 0.188504 Accuracy 100.00%\n",
      "Epoch   66/100 Cost: 0.192125 Accuracy 100.00%\n",
      "Epoch   67/100 Cost: 0.181179 Accuracy 100.00%\n",
      "Epoch   68/100 Cost: 0.182585 Accuracy 100.00%\n",
      "Epoch   69/100 Cost: 0.174504 Accuracy 100.00%\n",
      "Epoch   70/100 Cost: 0.174404 Accuracy 100.00%\n",
      "Epoch   71/100 Cost: 0.168540 Accuracy 100.00%\n",
      "Epoch   72/100 Cost: 0.167536 Accuracy 100.00%\n",
      "Epoch   73/100 Cost: 0.163315 Accuracy 100.00%\n",
      "Epoch   74/100 Cost: 0.161870 Accuracy 100.00%\n",
      "Epoch   75/100 Cost: 0.158812 Accuracy 100.00%\n",
      "Epoch   76/100 Cost: 0.157241 Accuracy 100.00%\n",
      "Epoch   77/100 Cost: 0.154967 Accuracy 100.00%\n",
      "Epoch   78/100 Cost: 0.153446 Accuracy 100.00%\n",
      "Epoch   79/100 Cost: 0.151679 Accuracy 100.00%\n",
      "Epoch   80/100 Cost: 0.150277 Accuracy 100.00%\n",
      "Epoch   81/100 Cost: 0.148826 Accuracy 100.00%\n",
      "Epoch   82/100 Cost: 0.147549 Accuracy 100.00%\n",
      "Epoch   83/100 Cost: 0.146290 Accuracy 100.00%\n",
      "Epoch   84/100 Cost: 0.145116 Accuracy 100.00%\n",
      "Epoch   85/100 Cost: 0.143973 Accuracy 100.00%\n",
      "Epoch   86/100 Cost: 0.142875 Accuracy 100.00%\n",
      "Epoch   87/100 Cost: 0.141804 Accuracy 100.00%\n",
      "Epoch   88/100 Cost: 0.140761 Accuracy 100.00%\n",
      "Epoch   89/100 Cost: 0.139740 Accuracy 100.00%\n",
      "Epoch   90/100 Cost: 0.138738 Accuracy 100.00%\n",
      "Epoch   91/100 Cost: 0.137754 Accuracy 100.00%\n",
      "Epoch   92/100 Cost: 0.136787 Accuracy 100.00%\n",
      "Epoch   93/100 Cost: 0.135835 Accuracy 100.00%\n",
      "Epoch   94/100 Cost: 0.134897 Accuracy 100.00%\n",
      "Epoch   95/100 Cost: 0.133973 Accuracy 100.00%\n",
      "Epoch   96/100 Cost: 0.133063 Accuracy 100.00%\n",
      "Epoch   97/100 Cost: 0.132166 Accuracy 100.00%\n",
      "Epoch   98/100 Cost: 0.131281 Accuracy 100.00%\n",
      "Epoch   99/100 Cost: 0.130409 Accuracy 100.00%\n",
      "Epoch  100/100 Cost: 0.129549 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs +1):\n",
    "    hypothesis = model(x_train)\n",
    "    cost= F.binary_cross_entropy(hypothesis, y_train)\n",
    "    optimizer.zero_grad() # grad를 구한게 있으면 0으로 처리\n",
    "    cost.backward() #cost에다가 backpropagation 수행\n",
    "    optimizer.step() #cost 값을 minimize하는 방향으로 업데이트를 한다. \n",
    "    if epoch % 1 == 0:\n",
    "        prediction = hypothesis>= torch.FloatTensor([0.5])\n",
    "        correct_prediction = prediction.float() == y_train\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n",
    "            epoch, nb_epochs,  cost.item(), accuracy * 100\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686499a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01531e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a077e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4f170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee789e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f633c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bbcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
